{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880e629e-b130-4ab1-aeac-24dc1eb17f5a",
   "metadata": {},
   "source": [
    "# HoloML in Stan: Low-photon Image Reconstruction\n",
    "### Brian Ward, Bob Carpenter, and David Barmherzig\n",
    "#### June 13, 2022\n",
    "\n",
    "This case study is a reimplementation of the algorithm described in Barmherzig and Sun (2022) [[1]](#References) as a Stan model. This requires the new features available in Stan 2.30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc43f7-03a1-4cac-9385-8c4959f07bd6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The HoloML technique is an approach to solving a specific kind of inverse problem inherent to imaging nanoscale specimens using X-ray diffraction. \n",
    "\n",
    "To solve this problem in Stan, we first write down the forward scientific model given by Barmherzig and Sun, including the Poisson photon distribution and censored data inherent to the physical problem, and then find a solution via penalized maximum likelihood.\n",
    "\n",
    "### Experimental setup \n",
    "\n",
    "In coherent diffraction imaging (CDI), a radiation source, typically an X-ray, is directed at a biomolecule or other specimen of interest, which causes diffraction. The resulting photon flux is measured by a far-field detector. The expected photon flux is approximately the squared magnitude of the Fourier transform of the electric field causing the diffraction. Inverting this to recover an image of the specimen is a problem usually known as *phase retrieval*. The phase retrieval problem is highly challenging and often lacks a unique solution [[2]](#References).\n",
    "\n",
    "Holographic coherent diffraction imaging (HCDI) is a variant in which the specimen is placed some distance away from a known reference object, and the data observed is the pattern of  diffraction around both the specimen and the reference. The addition of a reference object provides additional constraints on this problem, and transforms it into a linear deconvolution problem which has a unique, closed-form solution in the idealized setting [[3]](#References). \n",
    "\n",
    "The idealized version of HCDI is formulated as \n",
    "\n",
    "- Given a reference $R$, data $Y = | \\mathcal{F}( X + R ) | ^2$ \n",
    "- Recover the source image $X$\n",
    "\n",
    "Where $\\mathcal{F}$ is an oversampled Fourier transform operator.\n",
    "\n",
    "However, the real-world set up of these experiments introduces two additional difficulties. Data is measured from a limited number of photons, where the number of photons received by each detector is modeled as Poisson distributed with expectation given by $Y_{ij}$ (referred to in the paper as *Poisson-shot noise*). The expected number of photons each detector receives is denoted $N_p$. We typically have $N_p < 10$ due to the damage that radiation causes the biomolecule under observation. Secondly, to prevent damage to the detectors, the lowest frequencies are removed by a *beamstop*, which censors low-frequency observations. \n",
    "\n",
    "The maximum likelihood estimation of the model presented here is able to recover reasonable images even under a regime featuring low photon counts and a beamstop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8679ae1-e9d0-41c4-a73a-95bb561b7dfe",
   "metadata": {},
   "source": [
    "## Simulating Data\n",
    "\n",
    "We simulate data from the generative model directly. This corresponds to the approach taken by Barmherzig and Sun, and is based on MATLAB code provided by Barmherzig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ffc9e-5cf7-4a6b-a935-9126ea816f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports and helper code\n",
    "\n",
    "Generating the data requires a few standard Python numerical libraries such as scipy and numpy. Matplotlib is also used to simplify loading in the source image and displaying results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260fb8b-6a4b-4fc0-a956-fbecc4483264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import cmdstanpy\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Convert a nxmx3 RGB array to a grayscale nxm array.\n",
    "\n",
    "    This function uses the same internal coefficients as MATLAB:\n",
    "    https://www.mathworks.com/help/matlab/ref/rgb2gray.html\n",
    "    \"\"\"\n",
    "    r, g, b = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4b80e-fda7-4a8b-b369-66be7b477714",
   "metadata": {
    "tags": [
     "hide-code"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Extra display settings set, omitted from rendered case study\")\n",
    "\n",
    "# disable axes drawing, since we are showing images\n",
    "mpl.rc('axes.spines', top=False, bottom=False, left=False, right=False)\n",
    "mpl.rc('axes', facecolor='white')\n",
    "mpl.rc(\"xtick\", bottom=False, labelbottom=False)\n",
    "mpl.rc(\"ytick\", left=False, labelleft=False)\n",
    "\n",
    "# center images\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".jp-RenderedImage, .output_png{\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33fa51-143a-4a05-9119-eea801c548f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Simulation parameters\n",
    "\n",
    "To match the figures in the paper (in particular, Figure 9), we use an image of size 256x256, $N_p = 1$ (meaning each detector is expected to receive one photon), and a beamstop of size 25x25 (corresponding to a radius of 13), and a separation `d` equal to the size of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93efec2-328d-4669-99d8-6daddc804506",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "d = N\n",
    "N_p = 1\n",
    "r = 13\n",
    "\n",
    "M1 = 2 * N \n",
    "M2 = 2 * (2 * N + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89073a4-1be0-4cf2-9be6-bae2b3500b6e",
   "metadata": {},
   "source": [
    "We can then load the source image used for these simulations. In this model, the pixels of $X$ grayscale values represented on the interval [0, 1]. A conversion is done here from the standard RGBA encoding using the above `rgb2gray` function.\n",
    "\n",
    "The following is a picture of a [giant virus](https://en.wikipedia.org/wiki/Giant_virus) known as a mimivirus. \n",
    "\n",
    "Image credit: <a href=\"https://commons.wikimedia.org/wiki/File:Electron_microscopic_image_of_a_mimivirus_-_journal.ppat.1000087.g007_crop.png\">Ghigo E, Kartenbeck J, Lien P, Pelkmans L, Capo C, Mege JL, Raoult D.</a>, <a href=\"https://creativecommons.org/licenses/by/2.5\">CC BY 2.5</a>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8d50d-1d3c-4ee3-8811-aff16bbc9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_src = rgb2gray(mpimg.imread('mimivirus.png'))\n",
    "plt.imshow(X_src, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314a491-0fdb-4a0f-8e04-491d95d8b821",
   "metadata": {},
   "source": [
    "Additionally, we load in the pattern of the reference object. \n",
    "\n",
    "The pattern used here is known as a *uniformly redundant array* (URA) [[4]](#References). It has been shown to be an optimal reference image for this kind of work, but other references (including none at all) could be used with the same Stan model.\n",
    "\n",
    "The code used to generate this grid is omitted from this case study. Various options such as [cappy](https://github.com/bpops/cappy) exist to generate these patterns in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dccfa-177d-45b1-8f27-6177b5afba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.loadtxt('URA.csv', delimiter=\",\", dtype=int)\n",
    "plt.imshow(R, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e62a7fc-10f5-435c-94a8-48649c5f46d6",
   "metadata": {},
   "source": [
    "We create the specimen-reference hybrid image by concatenating the $X$ image, a matrix of zeros, and the reference $R$. In the true experiment, this is done by placing the specimen some distance `d` away from the reference, with opaque material between. \n",
    "\n",
    "This distance is typically the same as the size of the specimen, `N`. One contribution of the HoloML model is allowing recovery with the reference placed closer to the specimen, and the Stan model allows for this as well. \n",
    "\n",
    "For this simulation we use the separation of `d = N`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3aa37-f0eb-41ab-adf5-973c8b8034d0",
   "metadata": {
    "tags": [
     "hide-code"
    ]
   },
   "outputs": [],
   "source": [
    "mpl.rc(\"figure\", autolayout=True, figsize=(10.5, 7.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397dc9d-e8b4-4565-ae3b-a7fbe143d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0R = np.concatenate([X_src, np.zeros((N,d)), R], axis=1)\n",
    "plt.imshow(X0R, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb38a63-92ef-4362-b4c4-3688e8b7dba8",
   "metadata": {},
   "source": [
    "We can simulate the diffraction pattern of photons from the X-ray by taking the absolute value squared of the 2-dimensional oversampled FFT of this hybrid object. \n",
    "\n",
    "The oversampled FFT (denoted $\\mathcal{F}$ in the paper) corresponds to padding the image in both dimensions with zeros until it is a desired size. For our case, we define the size of the padded image, `M1` by `M2`, to be two times the size of our hybrid image, so the resulting FFT is twice oversampled. This is the oversampling ratio traditionally used for this problem, however Barmherzig and Sun also showed that this model can operate with less oversampling as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2925e-77be-4f30-9ea7-b979cf4931d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.abs(np.fft.fft2(X0R, s=(M1, M2))) ** 2\n",
    "plt.imshow(np.fft.fftshift(np.log1p(Y)), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c8f2fe-31e4-4016-9018-37dcfd12a8de",
   "metadata": {},
   "source": [
    "We simulate the photon fluxes with a Poisson pseudorandom number generator.\n",
    "\n",
    "This code specifies a fixed seed to ensure the same fake data is generated each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3fe7a-8b2c-4c76-ab20-377b4219e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = N_p / Y.mean()\n",
    "Y_tilde = stats.poisson.rvs(rate * Y, random_state=1234)\n",
    "plt.imshow(np.fft.fftshift(np.log1p(Y_tilde)), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129090e8-40bd-4b82-963e-834ae0774d6d",
   "metadata": {},
   "source": [
    "Finally, we need to remove the low frequency content of the data. This is caused in the physical experiment by the inclusion of a beamstop, which protects the instrument used by preventing the strongest parts of the beam from directly shining on the detectors.\n",
    "\n",
    "The beamstop is represented by $\\mathcal{B}$, a matrix of 0s and 1s. Zeros indicate that the data is occluded, while ones represent transparent portions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77193bce-dd6e-454f-b59e-135009fedf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_cal = np.ones((M1,M2), dtype=int)\n",
    "B_cal[M1 // 2 - r + 1: M1 // 2 + r, M2 // 2 - r + 1: M2 // 2 + r] = 0\n",
    "B_cal = np.fft.ifftshift(B_cal)\n",
    "# Sanity check\n",
    "assert (M1 * M2 - B_cal.sum()) == (( 2 * r - 1)**2)\n",
    "plt.imshow(np.fft.fftshift(B_cal), cmap=\"gray\", vmin=0, vmax=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06359fda-d7a4-4302-a63d-6abb97cb3d0c",
   "metadata": {},
   "source": [
    "We use this matrix $\\mathcal{B}$ to mask the low frequencies of the simulated data. After removing these elements from the simulated data, we have the final input which is used in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e40ec3-89bc-4544-9845-fbc53f53e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tilde *= B_cal\n",
    "plt.imshow(np.fft.fftshift(np.log1p(Y_tilde)), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7902cc-3ae9-4d2e-b3e8-0e9ebf4e4338",
   "metadata": {},
   "source": [
    "## Stan Model\n",
    "\n",
    "The Stan model code is a direct translation of the log density of the forward model described in the paper [[1]](#References) and above. The full model can be seen in the [appendix](#Appendix:-Full-Stan-Code).\n",
    "\n",
    "### Functions\n",
    "\n",
    "We define two helper functions to implement this model in Stan. The first is a function responsible for generating the $\\mathcal{B}$ matrix. Because Stan currently does not have FFT shifting functions, this is done by manually assigning to the corners of the matrix\n",
    "```stan\n",
    "functions {\n",
    "  matrix beamstop_gen(int M1, int M2, int r) {\n",
    "    matrix[M1, M2] B_cal = rep_matrix(1, M1, M2);\n",
    "\n",
    "    // upper left\n",
    "    B_cal[1 : r, 1 : r] = rep_matrix(0, r, r);\n",
    "    // upper right\n",
    "    B_cal[1 : r, M2 - r + 2 : M2] = rep_matrix(0, r, r - 1);\n",
    "    // lower left\n",
    "    B_cal[M1 - r + 2 : M1, 1 : r] = rep_matrix(0, r - 1, r);\n",
    "    // lower right\n",
    "    B_cal[M1 - r + 2 : M1, M2 - r + 2 : M2] = rep_matrix(0, r - 1, r - 1);\n",
    "    return B_cal;\n",
    "  }\n",
    "```\n",
    "\n",
    "The FFT described in the paper is an oversampled FFT. This corresponds to embedding the image in a larger array of zeros and results in a sort of interpolation between frequencies in the result. \n",
    "\n",
    "We write an overload of the `fft2` function which implements this behavior, similar to the signatures found in Matlab or Python libraries.\n",
    "\n",
    "```stan\n",
    "  complex_matrix fft2(complex_matrix Z, int N, int M) {\n",
    "    int r = rows(Z);\n",
    "    int c = cols(Z); \n",
    "    complex_matrix[N, M] pad = rep_matrix(0, N, M);\n",
    "    pad[1 : r, 1 : c] = Z;\n",
    "    \n",
    "    return fft2(pad);\n",
    "  }\n",
    "} // end functions block\n",
    "```\n",
    "\n",
    "Note that while the first input of this function is a `complex_matrix`, it will also accept real matrices due to the built-in type promotion in Stan.\n",
    "\n",
    "### Model inputs\n",
    "\n",
    "The Stan model needs the same information the generative model did, except it is supplied with $\\tilde{Y}$ instead of the source image $X$, plus a scale parameter for the prior, $\\sigma$. Smaller values of $\\sigma$ (approaching 0) lead to increasing amounts of blur in the resulting image.\n",
    "\n",
    "```stan\n",
    "data {\n",
    "  int<lower=0> N;                    // image dimension\n",
    "  matrix<lower=0, upper=1>[N, N] R;  // reference image\n",
    "  int<lower=0, upper=N> d;           // separation between sample and reference image\n",
    "  int<lower=N> M1;                   // rows of padded matrices\n",
    "  int<lower=2 * N + d> M2;           // cols of padded matrices\n",
    "  int<lower=0, upper=M1> r;          // beamstop radius. replaces omega1, omega2 in paper\n",
    "  \n",
    "  real<lower=0> N_p;                  // avg number of photons per pixel\n",
    "  array[M1, M2] int<lower=0> Y_tilde; // observed number of photons\n",
    "  \n",
    "  real<lower=0> sigma;                // standard deviation of pixel prior.\n",
    "}\n",
    "```\n",
    "\n",
    "The constraints listed above, such as `lower=0`, perform input validation. For example, the size of the padded FFT is, at a minimum, the size of the hybrid $X0R$ specimen, and we are able to encode this in the model with the lower bounds on `M1` and `M2`.\n",
    "\n",
    "\n",
    "### Additional fixed information\n",
    "\n",
    "Stan provides the ability to compute transformed data, values which depend on the inputs but only need to be evaluated once per model. This allows us to construct and store $\\mathcal{B}$ once, without recomputing it each iteration or requiring it as input.\n",
    "```stan\n",
    "transformed data {\n",
    "  matrix[M1, M2] B_cal = beamstop_gen(M1, M2, r);\n",
    "  matrix[d, N] separation = rep_matrix(0, d, N);\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Parameters\n",
    "\n",
    "This model has only one parameter, the image $X$. It is constrained to grayscale values between 0 and 1.\n",
    "```stan\n",
    "parameters {\n",
    "  matrix<lower=0, upper=1>[N, N] X;\n",
    "}\n",
    "```\n",
    "\n",
    "### Model code\n",
    "\n",
    "**Priors**\n",
    "\n",
    "We add a prior on $X$ to impose an L2 penalty on adjacent pixels. This induces a Gaussian blur on the result, and it is not strictly necessary for running the model. \n",
    "\n",
    "This prior is coded in our Stan program by looping over the rows and columns and using a vectorized call to the `normal` distribution. This results in each pixel being adjacent to 4 others. One could also formulate a prior which includes diagonally adjacent pixels\n",
    "\n",
    "\n",
    "```stan\n",
    "model {\n",
    "  for (i in 1 : rows(X) - 1) {\n",
    "    X[i] ~ normal(X[i + 1], sigma);\n",
    "  }\n",
    "  for (j in 1 : cols(X) - 1) {\n",
    "    X[ : , j] ~ normal(X[ : , j + 1], sigma);\n",
    "  }\n",
    "```\n",
    "\n",
    "**Likelihood**\n",
    "\n",
    "The model likelihood encodes the forward model. We construct the hybrid specimen, compute $|\\mathcal{F}(X0R)|^2$, and then compute the rate $\\lambda$ by scaling by the average number of photons $N_p$.\n",
    "\n",
    "We then loop over this result. If the current indices are not occluded by the beamstop $\\mathcal{B}$, we say that the data $\\tilde{Y}$ is distributed by a Poisson distribution with $\\lambda$ as the rate parameter.\n",
    "\n",
    "```stan  \n",
    "  // object representing specimen and reference together\n",
    "  matrix[N, 2 * N + d] X0R = append_col(X, append_col(separation, R));\n",
    "  // signal - squared magnitude of the (oversampled) FFT\n",
    "  matrix[M1, M2] Y = abs(fft2(X0R, M1, M2)) .^ 2;\n",
    "  \n",
    "  real N_p_over_Y_bar = N_p / mean(Y);\n",
    "  matrix[M1, M2] lambda = N_p_over_Y_bar * Y;\n",
    "  \n",
    "  for (m1 in 1 : M1) {\n",
    "    for (m2 in 1 : M2) {\n",
    "      if (B_cal[m1, m2]) {\n",
    "        Y_tilde[m1, m2] ~ poisson(lambda[m1, m2]);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "} // end model block\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd160cb7-6562-4d2e-9d4a-f648b251ecc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimization\n",
    "\n",
    "Now that we have our simulated data and our generative model, we solve the inverse problem. \n",
    "\n",
    "### Data preparation\n",
    "\n",
    "We prepare a dictionary of data corresponding to the models `data` block. This is mostly reusing constants defined earlier for the data simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add6dea-6a0e-427d-aab2-dbb5bd01055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1 # prior smoothing\n",
    "data = {\n",
    "    \"N\": N,\n",
    "    \"R\": R,\n",
    "    \"d\": N,\n",
    "    \"M1\": M1,\n",
    "    \"M2\": M2,\n",
    "    \"Y_tilde\": Y_tilde,\n",
    "    \"r\": r,\n",
    "    \"N_p\": N_p,\n",
    "    \"sigma\": sigma\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726a2e0-7a30-48ec-906f-45d192dbaf61",
   "metadata": {},
   "source": [
    "To run the model from Python, we instantiate it as a CmdStanModel object from cmdstanpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7a341-1d8e-47f0-bc69-2e5092b1e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "HoloML_model = cmdstanpy.CmdStanModel(stan_file=\"./holoml.stan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c794fb2-eaf6-4450-bf6e-a56503338357",
   "metadata": {},
   "source": [
    "Here we use optimization via the limited-memory quasi-Newton L-BFGS algorithm. This method has a bit more curvature information than what is available to the conjugate gradient approach, but less than the second order trust-region method used in the paper. This should take a few (1-3) minutes, depending on the machine you are running on.\n",
    "\n",
    "It is also possible to sample the model using the No-U-Turn Sampler (NUTS), but evaluations of this are out of the scope of this case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20463cb7-458f-43f0-bea7-ca0cba8b6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time fit = HoloML_model.optimize(data, inits=1, seed=5678)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2665ab-c96e-4bb0-bb34-5bf22109bb84",
   "metadata": {},
   "source": [
    "We use the function `stan_variable` to extract the maximum likelihood estimate (MLE) from the fit object returned by optimization.\n",
    "\n",
    "We can use this to plot the recovered image alongside the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d70f1-025e-4aa0-9b3c-f4978d8019bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1, 4, 1, title=\"Source Image\")\n",
    "ax1.imshow(X_src, cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 4, 2, title=\"Recovered Image\")\n",
    "ax2.imshow(fit.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c478511-fb2b-4988-8f66-9f0dc00f5c4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Varying $N_p$\n",
    "\n",
    "The above selection of $N_p=1$ is a reasonable choice for real experiment, but both smaller and larger numbers of expected photons may be used. The following are results for two other levels, $N_p = 0.1$ and $N_p = 10$\n",
    "\n",
    "This requires repeating the final few steps of the data generation and then re-fitting the model accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ae1c2-fdba-46b7-a421-9d333b7dbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_p = 0.1\n",
    "\n",
    "Y_tilde = stats.poisson.rvs((N_p / Y.mean()) * Y, random_state=1234) * B_cal\n",
    "\n",
    "data_fewer_photons = data.copy()\n",
    "data_fewer_photons['N_p'] = N_p\n",
    "data_fewer_photons['Y_tilde'] = Y_tilde\n",
    "\n",
    "%time fit_fewer_photons = HoloML_model.optimize(data_fewer_photons, inits=1, seed=5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b25ce-d829-4d69-bc74-779a68230cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_p = 10\n",
    "\n",
    "Y_tilde = stats.poisson.rvs((N_p / Y.mean()) * Y, random_state=1234) * B_cal\n",
    "\n",
    "data_more_photons = data.copy()\n",
    "data_more_photons['N_p'] = N_p\n",
    "data_more_photons['Y_tilde'] = Y_tilde\n",
    "\n",
    "%time fit_more_photons = HoloML_model.optimize(data_more_photons, inits=1, seed=5678)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e774d9-6a17-4ac6-8533-418cf0b7e9d1",
   "metadata": {},
   "source": [
    "It is worth noting that these two optimizations take very different amounts of time compared to the original, as the differing amounts of data yield posteriors which are more or less normal.\n",
    "\n",
    "In addition to the difference in runtime, the resulting images are very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0563f8-2083-41a2-b9a9-5e6ec829b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1, 4, 1, title=\"Source Image\")\n",
    "ax1.imshow(X_src, cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 4, 2, title=\"Recovered Image\\n($N_p=10$)\")\n",
    "ax2.imshow(fit_more_photons.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "ax3 = fig.add_subplot(1, 4, 3, title=\"Recovered Image\\n($N_p=1$)\")\n",
    "ax3.imshow(fit.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "ax4 = fig.add_subplot(1, 4, 4, title=\"Recovered Image\\n($N_p=0.1$)\")\n",
    "ax4.imshow(fit_fewer_photons.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e757be-d935-4c4d-b3be-b9228014fa21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prior tuning\n",
    "\n",
    "The above choice of $\\sigma = 1$ has a very slight effect on the output image.\n",
    "\n",
    "We also show the recovered image for $\\sigma = 20$, which provides even less smoothing than the above, and for $\\sigma = 0.05$. This smaller value imposes a greater penalty on adjacent pixels which are significantly different than each other, smoothing out the result.\n",
    "\n",
    "Each of these is done with the original value of $N_p = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff72fe2-ad71-40a6-9dd9-59fb68e05aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_weaker_prior = data.copy()\n",
    "data_weaker_prior['sigma'] = 20\n",
    "\n",
    "%time fit_rougher = HoloML_model.optimize(data_weaker_prior, inits=1, seed=5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d38b0-6488-49b2-b228-b9887ad7251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stronger_prior = data.copy()\n",
    "data_stronger_prior['sigma'] = 0.05\n",
    "\n",
    "%time fit_smooth = HoloML_model.optimize(data_stronger_prior, inits=1, seed=5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b9dee-096e-4cfb-89d2-4b6571499450",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(1, 4, 1, title=\"Source Image\")\n",
    "ax1.imshow(X_src, cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "ax2 = fig.add_subplot(1, 4, 2, title=\"Recovered Image\\n($\\sigma=0.05$)\")\n",
    "ax2.imshow(fit_smooth.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "ax3 = fig.add_subplot(1, 4, 3, title=\"Recovered Image\\n($\\sigma=1$)\")\n",
    "ax3.imshow(fit.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "ax4 = fig.add_subplot(1, 4, 4, title=\"Recovered Image\\n($\\sigma=20$)\")\n",
    "ax4.imshow(fit_rougher.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0783a-4536-496a-b802-e74515851912",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Barmherzig, D. A., & Sun, J. (2022). Towards practical holographic coherent diffraction imaging via maximum likelihood estimation. *Opt. Express, 30*(5), 6886–6906. doi:10.1364/OE.445015\n",
    "\n",
    "[2] Barnett, A. H., Epstein, C. L., Greengard, L. F., & Magland, J. F. (2020). Geometry of the phase retrieval problem. *Inverse Problems, 36*(9), 094003. doi:10.1088/1361-6420/aba5ed\n",
    "\n",
    "[3] Barmherzig, D. A., Sun, J., Li, P.-N., Lane, T. J., & Candès, E. J. (2019). Holographic phase retrieval and reference design. *Inverse Problems, 35*(9), 094001. doi:10.1088/1361-6420/ab23d1\n",
    "\n",
    "[4] Fenimore, E. E., & Cannon, T. M. (1978). Coded aperture imaging with uniformly redundant arrays. *Appl. Opt., 17*(3), 337–347. doi:10.1364/AO.17.000337"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e8d40-776b-4a71-9239-1285c22fe371",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Appendix: Full Stan Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e235be-80de-44c4-8ca5-ddfc7d68acc3",
   "metadata": {
    "tags": [
     "hide-code"
    ]
   },
   "outputs": [],
   "source": [
    "from pygments import highlight\n",
    "from pygments.lexers import StanLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "import IPython\n",
    "\n",
    "formatter = HtmlFormatter(style='tango')\n",
    "IPython.display.HTML('<style type=\"text/css\">{}</style>{}'.format(\n",
    "    formatter.get_style_defs('.highlight'),\n",
    "    highlight(HoloML_model.code(), StanLexer(), formatter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad03241-b9e9-4734-83a4-0d2ccb63656c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Digression: Efficiency\n",
    "\n",
    "The model above is coded for readability and sticks closely to the mathematical formulation of the process. However, this does lead to an inefficient condition inside the tightest loop of the model to handle the beamstop occlusion. \n",
    "\n",
    "In practice, it is possible to avoid this conditional by changing how the data is stored. Instead of storing the beamstop occlusion as a parallel matrix, we can pre-compute the list of indices which are included once and store it. Then, we can create flat representations of both the data $\\tilde{Y}$ and the rate $\\lambda$, allowing us to use a vectorized version of the Poisson distribution.\n",
    "\n",
    "```stan\n",
    "transformed data {\n",
    "  array[M1, M2] int B_cal = beamstop_gen(M1, M2, r);\n",
    "  int total = sum(to_array_1d(B_cal));\n",
    "  array[total, 2] idxs;\n",
    "  // pre-compute indices\n",
    "  int current = 1;\n",
    "  for (n in 1:M1){\n",
    "    for (m in 1:M2){\n",
    "      if (B_cal[n, m]){\n",
    "        idxs[current, :] = {n,m};\n",
    "        current += 1;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  // flatten data accordingly\n",
    "  array[total] int<lower=0> Ys;\n",
    "  for (n in 1:total) {\n",
    "    Ys[n] = Y_tilde[idxs[n, 1], idxs[n, 2]];\n",
    "  }\n",
    "}\n",
    "model {\n",
    "  // ... same code for computing matrix[M1, M2] lambda here\n",
    "  array[total] real lambdas;\n",
    "  for (n in 1:total) {\n",
    "    lambdas[n] = lambda[idxs[n, i], idxs[n, j]];  // much cheaper than branching\n",
    "  }\n",
    "\n",
    "  Ys ~ poisson(lambdas);  // fully vectorized\n",
    "}\n",
    "```\n",
    "\n",
    "This formulation of the model reduces the amount of time per gradient evaluation by 15-20%. A brief evaluation suggests however that the impact on optimization runtime is minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e876d80-0cd6-4eaa-9460-95369e28520a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reproducibility \n",
    "\n",
    "This notebook's source and related materials are available at https://github.com/WardBrian/holoml-in-stan.\n",
    "\n",
    "The following versions were used to produce this page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639004d-4f3f-438a-a122-6ae247018ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w\n",
    "print(\"CmdStan:\", cmdstanpy.utils.cmdstan_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0885d3-c718-4d9c-b419-8ac494cde50c",
   "metadata": {},
   "source": [
    "The rendered HTML output is produced with\n",
    "\n",
    "```\n",
    "jupyter nbconvert --to html \"HoloML in Stan.ipynb\" --template classic --TagRemovePreprocessor.remove_input_tags=hide-code -CSSHTMLHeaderPreprocessor.style=tango --execute\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40475740-b3db-490f-aeb0-18dea3ee10f0",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "899cba0b2aa3eec5edf045f75191ba79770627009f2daaa59e5a65b9c514bd7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
